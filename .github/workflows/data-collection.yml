name: Data Collection

# This workflow collects environmental data for Ontario.
#
# Usage:
#   1. Go to Actions > Data Collection > Run workflow
#   2. Select "collect" mode (default)
#   3. Check which data sources you want to collect
#   4. Click "Run workflow"
#
# By default, Williams Treaty Communities and Provincial Parks are selected.
# You can select additional data sources or deselect the defaults as needed.

on:
  workflow_dispatch:
    inputs:
      mode:
        description: 'Mode: status-only | collect-all | collect-selected'
        required: true
        type: choice
        options:
          - status-only
          - collect-all
          - collect-selected
        default: status-only
      datasets:
        description: 'Dataset IDs to collect (one per line or comma-separated). Run "status-only" first to see available datasets.'
        type: string
        required: false
        default: ''

jobs:
  check-status:
    name: Check Data Status
    runs-on: ubuntu-latest
    outputs:
      status: ${{ steps.check.outputs.status }}

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"

    - name: List available datasets from registry
      run: |
        echo "## üìã Available Datasets" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "The following datasets are available in the registry:" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        python3 << 'PYTHON_EOF'
        from ontario_data.datasets import get_enabled_datasets, DATASETS
        import os

        print("### Enabled Datasets")
        print("")
        for dataset in get_enabled_datasets():
            print(f"- `{dataset.id}` - {dataset.name}")

        print("")
        print("### Disabled Datasets")
        print("")
        for dataset_id, dataset in DATASETS.items():
            if not dataset.enabled:
                print(f"- ~~`{dataset_id}`~~ - {dataset.name} (disabled)")

        # Also write to GITHUB_STEP_SUMMARY
        with open(os.getenv('GITHUB_STEP_SUMMARY'), 'a') as f:
            f.write("### Enabled Datasets\n\n")
            for dataset in get_enabled_datasets():
                f.write(f"- `{dataset.id}` - {dataset.name}\n")
            f.write("\n### Disabled Datasets\n\n")
            for dataset_id, dataset in DATASETS.items():
                if not dataset.enabled:
                    f.write(f"- ~~`{dataset_id}`~~ - {dataset.name} (disabled)\n")
        PYTHON_EOF

    - name: Check existing data status
      id: check
      run: |
        # Run status check but don't fail - this is just informational
        set +e  # Don't exit on error
        python check_data_status.py
        # Ignore exit code - missing data before collection is expected

        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## üìä Current Data Status" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "Status check completed. Missing data is expected before collection." >> $GITHUB_STEP_SUMMARY

        # Always succeed - this is just informational
        exit 0

  collect-data:
    name: Collect Selected Data
    needs: check-status
    if: github.event.inputs.mode == 'collect'
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
    - uses: actions/checkout@v4

    - name: Show collection mode
      run: |
        echo "Collection mode: ${{ github.event.inputs.mode }}"
        if [ "${{ github.event.inputs.mode }}" == "collect-selected" ]; then
          echo "Selected datasets: ${{ github.event.inputs.datasets }}"
        fi

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"

    - name: Check before status
      run: |
        echo "=== DATA STATUS BEFORE COLLECTION ==="
        python check_data_status.py

    - name: Prepare data directories and files
      run: |
        # Create necessary directories
        mkdir -p data/raw data/processed

        # Download required CSV files if they don't exist
        # Note: Water advisories CSV - check if exists, if not download
        if [ ! -f "data/raw/water_advisories_historical.csv" ]; then
          echo "‚ö†Ô∏è  Water advisories CSV not found - will be skipped in collection"
          echo "   Download from: https://www.sac-isc.gc.ca/eng/1506514143353/1533317130660"
        fi

        # CWB CSV - check if exists
        if [ ! -f "data/raw/CWB_2021.csv" ]; then
          echo "‚ö†Ô∏è  Community Well-Being CSV not found - will be skipped in collection"
          echo "   Download from: https://www.sac-isc.gc.ca/eng/1419773101942/1419773233645"
        fi

        # Census boundaries shapefile - check if exists
        if [ ! -f "data/raw/lcsd000a21a_e.shp" ]; then
          echo "üì• Downloading Census Subdivision boundaries..."
          cd data/raw
          wget -q https://www12.statcan.gc.ca/census-recensement/2021/geo/sip-pis/boundary-limites/files-fichiers/lcsd000a21a_e.zip
          unzip -q lcsd000a21a_e.zip
          rm lcsd000a21a_e.zip
          cd ../..
          echo "‚úÖ Census boundaries downloaded"
        else
          echo "‚úÖ Census boundaries already exist"
        fi

    - name: Set environment variables for collection
      run: |
        echo "Mode: ${{ github.event.inputs.mode }}"

        if [ "${{ github.event.inputs.mode }}" == "collect-all" ]; then
          echo "Setting up to collect ALL enabled datasets from registry"
          python3 << 'PYTHON_EOF'
        import os
        from ontario_data.datasets import get_enabled_datasets

        # Write env vars to GITHUB_ENV
        env_file = os.getenv('GITHUB_ENV')
        with open(env_file, 'a') as f:
            for dataset in get_enabled_datasets():
                env_var = f'COLLECT_{dataset.id.upper()}'
                f.write(f'{env_var}=true\n')
                print(f'  ‚úì {env_var}=true')
        PYTHON_EOF

        elif [ "${{ github.event.inputs.mode }}" == "collect-selected" ]; then
          echo "Setting up to collect selected datasets"

          # Parse newline or comma-separated list
          datasets_input="${{ github.event.inputs.datasets }}"

          # Replace newlines with spaces and commas with spaces
          datasets_input=$(echo "$datasets_input" | tr '\n,' ' ')

          # Loop through each dataset ID
          for dataset_id in $datasets_input; do
            dataset_id=$(echo "$dataset_id" | xargs)  # trim whitespace
            if [ ! -z "$dataset_id" ]; then
              env_var="COLLECT_${dataset_id^^}"
              echo "${env_var}=true" >> $GITHUB_ENV
              echo "  ‚úì $dataset_id"
            fi
          done
        fi

    - name: Run data collection
      run: |
        echo "=========================================="
        echo "RUNNING DATA COLLECTION"
        echo "=========================================="
        python3 collect_data.py
      env:
        EBIRD_API_KEY: ${{ secrets.EBIRD_API_KEY }}


    - name: Check after status
      if: always()
      run: |
        echo ""
        echo "=== DATA STATUS AFTER COLLECTION ==="
        # Run status check (always exits 0, just reports data status)
        python check_data_status.py || true
        echo "Status check completed - see output above for details"

    - name: Upload data artifacts
      # Upload artifacts even if there were partial failures (but not if job was cancelled)
      if: github.event.inputs.upload_artifacts == 'true' && !cancelled()
      uses: actions/upload-artifact@v4
      with:
        name: ontario-data-${{ github.run_number }}
        path: |
          data/processed/**/*.geojson
          data/processed/**/*.json
          data/processed/**/*.csv
          data/processed/collection_report.json
          data_status.json
        retention-days: 30
        if-no-files-found: warn

    - name: Create collection summary
      if: always()
      run: |
        echo "## üì¶ Data Collection Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Run:** #${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
        echo "**Status:** ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
        echo "**Force Refresh:** ${{ github.event.inputs.force_refresh }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        echo "### Selected Data Sources" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Data Source | Selected |" >> $GITHUB_STEP_SUMMARY
        echo "|-------------|----------|" >> $GITHUB_STEP_SUMMARY
        echo "| Williams Treaty Communities | ${{ github.event.inputs.williams_treaty_communities == 'true' && '‚úÖ' || '‚¨ú' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Williams Treaty Boundaries | ${{ github.event.inputs.williams_treaty_boundaries == 'true' && '‚úÖ' || '‚¨ú' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Water Advisories | ${{ github.event.inputs.water_advisories == 'true' && '‚úÖ' || '‚¨ú' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Fire Perimeters | ${{ github.event.inputs.fire_perimeters == 'true' && '‚úÖ' || '‚¨ú' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Provincial Parks | ${{ github.event.inputs.provincial_parks == 'true' && '‚úÖ' || '‚¨ú' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Conservation Authorities | ${{ github.event.inputs.conservation_authorities == 'true' && '‚úÖ' || '‚¨ú' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| iNaturalist | ${{ github.event.inputs.inaturalist == 'true' && '‚úÖ' || '‚¨ú' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| eBird | ${{ github.event.inputs.ebird == 'true' && '‚úÖ' || '‚¨ú' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Community Well-Being | ${{ github.event.inputs.community_wellbeing == 'true' && '‚úÖ' || '‚¨ú' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Watersheds | ${{ github.event.inputs.watersheds == 'true' && '‚úÖ' || '‚¨ú' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Satellite Data | ${{ github.event.inputs.satellite == 'true' && '‚úÖ' || '‚¨ú' }} |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        echo "### Collection Report" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "Full data collection script (collect_all_data.py) was executed." >> $GITHUB_STEP_SUMMARY
        echo "All available data sources were attempted." >> $GITHUB_STEP_SUMMARY
        echo "See collection_report.json for detailed results." >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        if [ -f "data/processed/collection_report.json" ]; then
          echo "### Collection Results" >> $GITHUB_STEP_SUMMARY
          echo '```json' >> $GITHUB_STEP_SUMMARY
          cat data/processed/collection_report.json | python -m json.tool 2>/dev/null || cat data/processed/collection_report.json
          echo '```' >> $GITHUB_STEP_SUMMARY
        fi

        if [ -f "data_status.json" ]; then
          echo "### Final Data Status" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          python check_data_status.py 2>&1 | tail -20
          echo '```' >> $GITHUB_STEP_SUMMARY
        fi
